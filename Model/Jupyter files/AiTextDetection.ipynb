{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2807d465-41cf-49a8-9c39-7dc9b842ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47051eb-95e3-404f-8913-8c65d657852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing datasets\n",
    "train_essays = pd.read_csv(\"../data/train_essays.csv\")\n",
    "test_essays = pd.read_csv(\"../data/test_essays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7feeacc7-2ed9-46b6-aa09-bf5f7cf33d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1378 entries, 0 to 1377\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         1378 non-null   object\n",
      " 1   prompt_id  1378 non-null   int64 \n",
      " 2   text       1378 non-null   object\n",
      " 3   generated  1378 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 43.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Explore the training data\n",
    "train_essays.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2a4b69-1b23-4522-bc86-7fc2fa191f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0059830c</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005db917</td>\n",
       "      <td>0</td>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f63e3</td>\n",
       "      <td>0</td>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00940276</td>\n",
       "      <td>0</td>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c39458</td>\n",
       "      <td>0</td>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  prompt_id                                               text  \\\n",
       "0  0059830c          0  Cars. Cars have been around since they became ...   \n",
       "1  005db917          0  Transportation is a large necessity in most co...   \n",
       "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
       "3  00940276          0  How often do you ride in a car? Do you drive a...   \n",
       "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
       "\n",
       "   generated  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc17796b-87d8-4bb1-94da-58176e7941a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check for class balance\n",
    "sns.countplot(data=train_essays, x='generated')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87447085-4b6c-4cf6-9fa4-4e9b9d94c858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n",
    "    words = text.split()  # Tokenize\n",
    "    words = [word.lower() for word in words if word.isalpha()]  # Lowercase and remove non-alphabetic words\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stop words\n",
    "    return ' '.join(words)\n",
    "\n",
    "train_essays['clean_text'] = train_essays['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4b4332-4f11-49c8-9888-39fb60d791a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_essays['clean_text'], train_essays['generated'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec0b741-4eb9-4f60-98c8-98785db398aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Encoding for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, padding=True, truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4da3b4e-0728-4f57-8fcc-d301a4d15b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "encoded_val = tokenizer(X_val.tolist(), padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24943d6e-9353-4782-9dc3-fbcf30970166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to tensors\n",
    "train_labels = torch.tensor(y_train.values)\n",
    "val_labels = torch.tensor(y_val.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c563b382-e7fb-44d7-9f3e-54bdc4ff0f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\n",
    "val_dataset = TensorDataset(encoded_val['input_ids'], encoded_val['attention_mask'], val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf3cd6ae-7632-4bc7-8aaa-884e2f4a229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader for efficient processing\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True, num_workers=8, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6848a7db-fd91-4f71-8456-e4ec71082e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "# Define the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67077bb8-33f4-4827-85af-b3b8234803c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False, no_deprecation_warning=True)\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5be4c24-fecf-4e0d-919a-71437feb9dd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      4\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m      7\u001b[0m     input_ids, attention_mask, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m      8\u001b[0m     input_ids, attention_mask, labels \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device), attention_mask\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32md:\\Detect-AI-Generated-Text\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\Detect-AI-Generated-Text\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1327\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Detect-AI-Generated-Text\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1293\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1289\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1293\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1294\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1295\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32md:\\Detect-AI-Generated-Text\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1131\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:330\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    328\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:879\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    876\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m    877\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 879\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\multiprocessing\\connection.py:811\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    809\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m--> 811\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to avoid exploding gradients\n",
    "        optimizer.step()\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51542514-ea85-4a17-8b00-208d3278aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loop\n",
    "model.eval()\n",
    "val_preds = []\n",
    "val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        val_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "        val_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df213f18-4cc1-490c-a0f0-dcdb7bfd3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate validation accuracy\n",
    "val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a75af-5cfe-4b83-b48b-1742ce822b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data processing\n",
    "test_inputs = tokenizer(test_essays['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Move input tensor to the same device as the model\n",
    "test_inputs = {key: value.to(device) for key, value in test_inputs.items()}\n",
    "\n",
    "# Generate predictions using your trained model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**test_inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Assuming the first column of logits corresponds to the negative class (non-AI-generated) \n",
    "# and the second column corresponds to the positive class (AI-generated)\n",
    "predictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Move predictions back to CPU\n",
    "\n",
    "# Create a submission DataFrame with essay IDs and corresponding predictions\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_essays['id'],\n",
    "    'generated': predictions\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AiTextDetection",
   "language": "python",
   "name": "aitextdetection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
